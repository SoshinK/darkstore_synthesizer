{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3kdi7DbKWns"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_d3BsUjkKSuK",
    "outputId": "423a8fee-4c4b-4d79-f753-06bdd5248a0e"
   },
   "outputs": [],
   "source": [
    "# setup vulkan\n",
    "!mkdir -p /usr/share/vulkan/icd.d\n",
    "!wget -q https://raw.githubusercontent.com/haosulab/ManiSkill/main/docker/nvidia_icd.json\n",
    "!wget -q https://raw.githubusercontent.com/haosulab/ManiSkill/main/docker/10_nvidia.json\n",
    "!mv nvidia_icd.json /usr/share/vulkan/icd.d\n",
    "!mv 10_nvidia.json /usr/share/glvnd/egl_vendor.d/10_nvidia.json\n",
    "!apt-get install -y --no-install-recommends libvulkan-dev\n",
    "# dependencies\n",
    "!pip install --upgrade mani_skill tyro\n",
    "!pip install sapien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1qtqv4EKaCf"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    import site\n",
    "    site.main() # run this so local pip installs are recognized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY_gz9g8LNMH"
   },
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dto7MnOmMRka",
    "outputId": "7c26a299-3ca9-4f66-eb4f-149bef6af11d"
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import gymnasium as gym\n",
    "import mani_skill.envs\n",
    "import torch\n",
    "import time\n",
    "num_envs = 512 # you can go up higher on better GPUs, this is mostly memory constrained\n",
    "env = gym.make(\"PickCube-v1\", num_envs=num_envs, obs_mode=\"rgbd\")\n",
    "env.unwrapped.print_sim_details()\n",
    "obs, _ = env.reset(seed=0)\n",
    "done = False\n",
    "start_time = time.time()\n",
    "total_rew = 0\n",
    "while not done:\n",
    "    # note that env.action_space is now a batched action space\n",
    "    obs, rew, terminated, truncated, info = env.step(torch.from_numpy(env.action_space.sample()))\n",
    "    done = (terminated | truncated).any() # stop if any environment terminates/truncates\n",
    "N = num_envs * info[\"elapsed_steps\"][0].item()\n",
    "dt = time.time() - start_time\n",
    "FPS = N / (dt)\n",
    "print(f\"Frames Per Second = {N} / {dt} = {FPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "8eVbxMpLMWXB",
    "outputId": "2753b259-9226-41e8-dedb-42a3a8849a98"
   },
   "outputs": [],
   "source": [
    "# visualize the image data from the environment and inspect the data\n",
    "print(obs.keys())\n",
    "print(obs['sensor_data'].keys())\n",
    "print(obs['sensor_data']['base_camera'].keys())\n",
    "print(obs['sensor_data']['base_camera']['rgb'].shape)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(obs['sensor_data']['base_camera']['rgb'][0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5Z7A6OqKdzB"
   },
   "source": [
    "### Shit class\n",
    "Right here you need to change MyEnv to smth other if updating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 737
    },
    "id": "JBgtCoQjKlOh",
    "outputId": "89ed797d-1d34-4627-e17f-e8498f786caa"
   },
   "outputs": [],
   "source": [
    "\n",
    "from mani_skill.envs.tasks.empty_env import EmptyEnv\n",
    "from mani_skill.envs.sapien_env import BaseEnv\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "from mani_skill.agents.robots.fetch import FETCH_WHEELS_COLLISION_BIT\n",
    "from mani_skill.utils.building.ground import build_ground\n",
    "# from mani_skill.utils.scene_builder import SceneBuilder\n",
    "from mani_skill.utils.registration import register_env\n",
    "from mani_skill.utils import common, sapien_utils\n",
    "import sapien\n",
    "from mani_skill.sensors.camera import CameraConfig\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import mani_skill.envs\n",
    "from tqdm import tqdm\n",
    "from mani_skill.utils.wrappers import RecordEpisode\n",
    "\n",
    "ENV_NAME =\"MyEmptyEnv5\"\n",
    "\n",
    "@register_env(ENV_NAME, max_episode_steps=200000)\n",
    "class MyEmptyEnv(BaseEnv):\n",
    "    SUPPORTED_REWARD_MODES = [\"none\"]\n",
    "    \"\"\"\n",
    "    This is just a dummy environment for showcasing robots in a empty scene\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, robot_uids=\"panda\", **kwargs):\n",
    "        super().__init__(*args, robot_uids=robot_uids, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def _default_sensor_configs(self):\n",
    "        pose = sapien_utils.look_at([1.25, -1.25, 1.5], [0.0, 0.0, 0.2])\n",
    "        return [CameraConfig(\"base_camera\", pose, 128, 128, np.pi / 2, 0.01, 100)]\n",
    "\n",
    "    @property\n",
    "    def _default_human_render_camera_configs(self):\n",
    "        pose = sapien_utils.look_at([1.25, -1.25, 1.5], [0.0, 0.0, 0.2])\n",
    "        return CameraConfig(\"render_camera\", pose, 2048, 2048, 1, 0.01, 100)\n",
    "\n",
    "    def _load_agent(self, options: dict):\n",
    "        super()._load_agent(options, sapien.Pose(p=[-0.615, 0, 0]))\n",
    "\n",
    "    def _load_scene(self, options: dict):\n",
    "        self.ground = build_ground(self.scene)\n",
    "        self.ground.set_collision_group_bit(group=2, bit_idx=30, bit=1)\n",
    "\n",
    "\n",
    "        #===============================\n",
    "        # Load URDF articuation\n",
    "        #===============================\n",
    "        loader = self.scene.create_urdf_loader()\n",
    "        articulation_builders = loader.parse(str('./scene.urdf'))[\"articulation_builders\"]\n",
    "        builder = articulation_builders[0]\n",
    "\n",
    "        builder.initial_pose = sapien.Pose(p=[0, 0, 0.5])\n",
    "        builder.build(name=\"my_articulation\")\n",
    "\n",
    "\n",
    "        #===============================\n",
    "        # Load actor from glb\n",
    "        #===============================\n",
    "        # scale=np.array([1.0, 1.0, 1.0])\n",
    "        # builder = self.scene.create_actor_builder()\n",
    "        # builder.add_convex_collision_from_file(\n",
    "        #     filename=\"/home/kvsoshin/Work/AIRI/ManiSkill/textures/milk_carton.glb\",\n",
    "        #     scale=scale\n",
    "        # )\n",
    "        # builder.add_visual_from_file(filename=\"/home/kvsoshin/Work/AIRI/ManiSkill/textures/milk_carton.glb\", scale=scale)\n",
    "        # builder.set_initial_pose(sapien.Pose(p=[0.0, 0.0, 0.0]))\n",
    "        # self.mesh = builder.build_static(name=\"mesh\")\n",
    "\n",
    "\n",
    "\n",
    "    def _initialize_episode(self, env_idx: torch.Tensor, options: dict):\n",
    "        if self.robot_uids == \"fetch\":\n",
    "            qpos = np.array(\n",
    "                [\n",
    "                    0,\n",
    "                    0,\n",
    "                    0,\n",
    "                    0.386,\n",
    "                    0,\n",
    "                    0,\n",
    "                    0,\n",
    "                    -np.pi / 4,\n",
    "                    0,\n",
    "                    np.pi / 4,\n",
    "                    0,\n",
    "                    np.pi / 3,\n",
    "                    0,\n",
    "                    0.015,\n",
    "                    0.015,\n",
    "                ]\n",
    "            )\n",
    "            self.agent.reset(qpos)\n",
    "            self.agent.robot.set_pose(sapien.Pose([10.0, 10, 0.0]))\n",
    "\n",
    "            self.ground.set_collision_group_bit(\n",
    "                group=2, bit_idx=FETCH_WHEELS_COLLISION_BIT, bit=1\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {}\n",
    "\n",
    "    def _get_obs_extra(self, info: Dict):\n",
    "        return dict()\n",
    "\n",
    "\n",
    "env = gym.make(ENV_NAME, robot_uids='fetch', num_envs=1, render_mode=\"rgb_array\", enable_shadow=True)\n",
    "\n",
    "pose = sapien_utils.look_at([3.25, -3.25, 1.5], [0.0, 0.0, 0.2])\n",
    "env._default_human_render_camera_configs = CameraConfig(\"render_camera\", pose, 2048, 2048, 1, 0.01, 100)\n",
    "\n",
    "env = RecordEpisode(\n",
    "    env,\n",
    "    \"./videos\", # the directory to save replay videos and trajectories to\n",
    "    # on GPU sim we record intervals, not by single episodes as there are multiple envs\n",
    "    # each 100 steps a new video is saved\n",
    "    max_steps_per_video=100\n",
    ")\n",
    "\n",
    "# step through the environment with random actions\n",
    "obs, _ = env.reset()\n",
    "\n",
    "\n",
    "viewer = env.render()\n",
    "if isinstance(viewer, sapien.utils.Viewer):\n",
    "    viewer.paused = False\n",
    "env.render()\n",
    "\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(torch.zeros_like(torch.from_numpy(action)))\n",
    "\n",
    "    env.render()\n",
    "    # env.render_human() # will render with a window if possible\n",
    "env.close()\n",
    "from IPython.display import Video\n",
    "Video(\"./videos/0.mp4\", embed=True, width=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2ob3wyxSwUm"
   },
   "source": [
    "### Base env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omVRCa8GSvyQ"
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import sapien\n",
    "import torch\n",
    "\n",
    "from mani_skill.agents.robots.fetch.fetch import Fetch\n",
    "from mani_skill.agents.robots.panda.panda import Panda\n",
    "from mani_skill.envs.sapien_env import BaseEnv\n",
    "from mani_skill.sensors.camera import CameraConfig\n",
    "from mani_skill.utils import sapien_utils\n",
    "from mani_skill.utils.building.ground import build_ground\n",
    "from mani_skill.utils.registration import register_env\n",
    "from mani_skill.utils.structs.types import GPUMemoryConfig, SimConfig\n",
    "\n",
    "\n",
    "@register_env(\"Empty-v3\", max_episode_steps=200000)\n",
    "class EmptyEnv(BaseEnv):\n",
    "    SUPPORTED_REWARD_MODES = [\"none\"]\n",
    "    \"\"\"\n",
    "    This is just a dummy environment for showcasing robots in a empty scene\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, robot_uids=\"fetch\", **kwargs):\n",
    "        super().__init__(*args, robot_uids=robot_uids, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def _default_sensor_configs(self):\n",
    "        pose = sapien_utils.look_at([1.25, -1.25, 1.5], [0.0, 0.0, 0.2])\n",
    "        return [CameraConfig(\"base_camera\", pose, 128, 128, np.pi / 2, 0.01, 100)]\n",
    "\n",
    "    @property\n",
    "    def _default_human_render_camera_configs(self):\n",
    "        pose = sapien_utils.look_at([1.25, -1.25, 1.5], [0.0, 0.0, 0.2])\n",
    "        return CameraConfig(\"render_camera\", pose, 2048, 2048, 1, 0.01, 100)\n",
    "\n",
    "    def _load_agent(self, options: dict):\n",
    "        super()._load_agent(options, sapien.Pose())\n",
    "\n",
    "    def _load_scene(self, options: dict):\n",
    "        self.ground = build_ground(self.scene)\n",
    "        self.ground.set_collision_group_bit(group=2, bit_idx=30, bit=1)\n",
    "\n",
    "    def _initialize_episode(self, env_idx: torch.Tensor, options: dict):\n",
    "        pass\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {}\n",
    "\n",
    "    def _get_obs_extra(self, info: Dict):\n",
    "        return dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OESJDWu_OtuZ"
   },
   "source": [
    "### Try Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462,
     "referenced_widgets": [
      "d8868caf10f643d59d077133ebc33c9f",
      "6c53cd786859491ca68a922ff67b4062",
      "89d9889ccbd2483d8288eae55adfa4e8",
      "4500d203fff44d2fafe5a318181fefde",
      "b9ec0f32ec164e8b932b754eeee6c47b",
      "5bb10dd4d5224b98a3de338e70b7660f",
      "2bfa4890a6fb4829b25e5f24fa3b7a01",
      "ab41380dff40469b8433794ece212c58",
      "35d5dc6de0d24abc8c265a56f227fd22",
      "c8025b900077410f8687234e3aefd00b",
      "b9cc143db1c84ddb9801b701ecd64be8"
     ]
    },
    "id": "G7xSrX4gOtWI",
    "outputId": "aa6ac472-166e-41e8-af32-c3cc9965b0ce"
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import mani_skill.envs\n",
    "from tqdm.notebook import tqdm\n",
    "from mani_skill.utils.wrappers import RecordEpisode\n",
    "# to make it look a little more realistic, we will enable shadows which make the default lighting cast shadows\n",
    "env = gym.make(\"MyEnv1\", num_envs=1, render_mode=\"rgb_array\", enable_shadow=True)\n",
    "env = RecordEpisode(\n",
    "    env,\n",
    "    \"./videos\", # the directory to save replay videos and trajectories to\n",
    "    # on GPU sim we record intervals, not by single episodes as there are multiple envs\n",
    "    # each 100 steps a new video is saved\n",
    "    max_steps_per_video=100\n",
    ")\n",
    "\n",
    "# step through the environment with random actions\n",
    "obs, _ = env.reset()\n",
    "for i in tqdm(range(100)):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(torch.from_numpy(action))\n",
    "    # env.render_human() # will render with a window if possible\n",
    "env.close()\n",
    "from IPython.display import Video\n",
    "Video(\"./videos/0.mp4\", embed=True, width=640) # Watch our replay"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2bfa4890a6fb4829b25e5f24fa3b7a01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35d5dc6de0d24abc8c265a56f227fd22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4500d203fff44d2fafe5a318181fefde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8025b900077410f8687234e3aefd00b",
      "placeholder": "​",
      "style": "IPY_MODEL_b9cc143db1c84ddb9801b701ecd64be8",
      "value": " 0/100 [00:00&lt;?, ?it/s]"
     }
    },
    "5bb10dd4d5224b98a3de338e70b7660f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c53cd786859491ca68a922ff67b4062": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bb10dd4d5224b98a3de338e70b7660f",
      "placeholder": "​",
      "style": "IPY_MODEL_2bfa4890a6fb4829b25e5f24fa3b7a01",
      "value": "  0%"
     }
    },
    "89d9889ccbd2483d8288eae55adfa4e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab41380dff40469b8433794ece212c58",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_35d5dc6de0d24abc8c265a56f227fd22",
      "value": 0
     }
    },
    "ab41380dff40469b8433794ece212c58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9cc143db1c84ddb9801b701ecd64be8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9ec0f32ec164e8b932b754eeee6c47b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8025b900077410f8687234e3aefd00b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8868caf10f643d59d077133ebc33c9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c53cd786859491ca68a922ff67b4062",
       "IPY_MODEL_89d9889ccbd2483d8288eae55adfa4e8",
       "IPY_MODEL_4500d203fff44d2fafe5a318181fefde"
      ],
      "layout": "IPY_MODEL_b9ec0f32ec164e8b932b754eeee6c47b"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
